{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_text_file = open(\"sample1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = my_text_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ireland's economy is now booming and it's growth is now the highest in Europe with 7.8%, and the value of the Irish economy is now close to Ã¢â€šÂ¬300 billion.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_obj = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ireland PROPN poss False Xxxxx\n",
      "'s PART case False 'x\n",
      "economy NOUN nsubj False xxxx\n",
      "is VERB aux True xx\n",
      "now ADV advmod True xxx\n",
      "booming ADJ ROOT False xxxx\n",
      "and CCONJ cc True xxx\n",
      "it PRON poss True xx\n",
      "'s VERB case False 'x\n",
      "growth NOUN nsubj False xxxx\n",
      "is VERB conj True xx\n",
      "now ADV advmod True xxx\n",
      "the DET det True xxx\n",
      "highest ADJ attr False xxxx\n",
      "in ADP prep True xx\n",
      "Europe PROPN pobj False Xxxxx\n",
      "with ADP prep True xxxx\n",
      "7.8 NUM nummod False d.d\n",
      "% NOUN pobj False %\n",
      ", PUNCT punct False ,\n",
      "and CCONJ cc True xxx\n",
      "the DET det True xxx\n",
      "value NOUN nsubj False xxxx\n",
      "of ADP prep True xx\n",
      "the DET det True xxx\n",
      "Irish ADJ amod False Xxxxx\n",
      "economy NOUN pobj False xxxx\n",
      "is VERB conj True xx\n",
      "now ADV advmod True xxx\n",
      "close ADJ acomp False xxxx\n",
      "to ADP prep True xx\n",
      "Ã¢â€šÂ¬300 PROPN compound False X¢x€xX¬ddd\n",
      "billion NUM pobj False xxxx\n",
      ". PUNCT punct False .\n"
     ]
    }
   ],
   "source": [
    "for token in document_obj:\n",
    "    print(token.text, token.pos_, token.dep_, token.is_stop, token.shape_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adposition'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"ADP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_obj = nlp(u\"\"\"All the world's a stage. And all the men and women are merely players. They have their exits and their entrances; and one man in his time plays many parts. - Shakespeare\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And all the men and women are merely players\n"
     ]
    }
   ],
   "source": [
    "sentence = doc_obj[7:16]\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the world's a stage.\n",
      "And all the men and women are merely players.\n",
      "They have their exits and their entrances; and one man in his time plays many parts.\n",
      "- Shakespeare\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc_obj.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "all"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_obj[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(doc_obj[8].is_sent_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None   All\n",
      "None   the\n",
      "None   world\n",
      "None   's\n",
      "None   a\n",
      "None   stage\n",
      "None   .\n",
      "True   And\n",
      "None   all\n",
      "None   the\n",
      "None   men\n",
      "None   and\n",
      "None   women\n",
      "None   are\n",
      "None   merely\n",
      "None   players\n",
      "None   .\n",
      "True   They\n",
      "None   have\n",
      "None   their\n",
      "None   exits\n",
      "None   and\n",
      "None   their\n",
      "None   entrances\n",
      "None   ;\n",
      "None   and\n",
      "None   one\n",
      "None   man\n",
      "None   in\n",
      "None   his\n",
      "None   time\n",
      "None   plays\n",
      "None   many\n",
      "None   parts\n",
      "None   .\n",
      "True   -\n",
      "None   Shakespeare\n"
     ]
    }
   ],
   "source": [
    "for token in doc_obj:\n",
    "    print(token.is_sent_start, \" \", token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "All the world's a stage. And all the men and women are merely players. They have their exits and their entrances; and one man in his time plays many parts. -"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_obj[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All\n",
      "the\n",
      "world\n",
      "'s\n",
      "a\n",
      "stage\n",
      ".\n",
      "And\n",
      "all\n",
      "the\n",
      "men\n",
      "and\n",
      "women\n",
      "are\n",
      "merely\n",
      "players\n",
      ".\n",
      "They\n",
      "have\n",
      "their\n",
      "exits\n",
      "and\n",
      "their\n",
      "entrances\n",
      ";\n",
      "and\n",
      "one\n",
      "man\n",
      "in\n",
      "his\n",
      "time\n",
      "plays\n",
      "many\n",
      "parts\n",
      ".\n",
      "-\n",
      "Shakespeare\n"
     ]
    }
   ],
   "source": [
    "for token in doc_obj:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to add a new segmentation rule\n",
    "def create_custom_sentence_boundary(document_obj):\n",
    "    # check each word up until the second last word\n",
    "    for token in document_obj[:-1]:\n",
    "        # if the token = \";\" then set the next token as start token\n",
    "        if token.text == \";\":\n",
    "            document_obj[token.i+1].is_sent_start = True\n",
    "    return document_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E043] Refusing to write to token.sent_start if its document is parsed, because this may cause inconsistent state.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-8793114da45d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdoc_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_custom_sentence_boundary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc_obj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sent_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-48-a42c3cec6ebf>\u001b[0m in \u001b[0;36mcreate_custom_sentence_boundary\u001b[1;34m(document_obj)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;31m# if the token = \";\" then set the next token as start token\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\";\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m             \u001b[0mdocument_obj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sent_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdocument_obj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mtoken.pyx\u001b[0m in \u001b[0;36mspacy.tokens.token.Token.is_sent_start.__set__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E043] Refusing to write to token.sent_start if its document is parsed, because this may cause inconsistent state."
     ]
    }
   ],
   "source": [
    "doc_obj = create_custom_sentence_boundary(doc_obj)\n",
    "for token in doc_obj:\n",
    "    print(token.is_sent_start, \" \", token.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
