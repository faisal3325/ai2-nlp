{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing sentence1.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile sentence1.txt\n",
    "I really like this NLP module now!\n",
    "Letterkenny is a great town.\n",
    "I would like to go for a coffee now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing sentence2.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile sentence2.txt\n",
    "I like to go shopping and to have a coffee.\n",
    "Is it far to the town from here?\n",
    "NLP is not complicated in this module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i': 1, 'really': 2, 'like': 3, 'this': 4, 'nlp': 5, 'module': 6, 'now!': 7, 'letterkenny': 8, 'is': 9, 'a': 10, 'great': 11, 'town.': 12, 'would': 13, 'to': 14, 'go': 15, 'for': 16, 'coffee': 17, 'now.': 18}\n"
     ]
    }
   ],
   "source": [
    "vocab_dictionary = {}\n",
    "counter = 1\n",
    "\n",
    "with open('sentence1.txt') as file:\n",
    "    sentence_file = file.read().lower().split()\n",
    "\n",
    "for word in sentence_file:\n",
    "    # if the word is already present then skip\n",
    "    if word in vocab_dictionary:\n",
    "        continue\n",
    "    # If the word doesnt exists in the dictionary, add it with a \n",
    "    # uniques counter (index) number\n",
    "    else:\n",
    "        vocab_dictionary[word]=counter\n",
    "        counter+=1\n",
    "\n",
    "print(vocab_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i': 1, 'really': 2, 'like': 3, 'this': 4, 'nlp': 5, 'module': 6, 'now!': 7, 'letterkenny': 8, 'is': 9, 'a': 10, 'great': 11, 'town.': 12, 'would': 13, 'to': 14, 'go': 15, 'for': 16, 'coffee': 17, 'now.': 18, 'shopping': 19, 'and': 20, 'have': 21, 'coffee.': 22, 'it': 23, 'far': 24, 'the': 25, 'town': 26, 'from': 27, 'here?': 28, 'not': 29, 'complicated': 30, 'in': 31, 'module.': 32}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('sentence2.txt') as file:\n",
    "    sentence_file = file.read().lower().split()\n",
    "\n",
    "for word in sentence_file:\n",
    "    if word in vocab_dictionary:\n",
    "        continue\n",
    "    else:\n",
    "        vocab_dictionary[word]=counter\n",
    "        counter+=1\n",
    "\n",
    "print(vocab_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentence 1', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['sentence 2', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "one = ['sentence 1']+[0]*len(vocab_dictionary)\n",
    "print(one)\n",
    "\n",
    "two = ['sentence 2']+[0]*len(vocab_dictionary)\n",
    "print(two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentence 1', 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# map the frequencies of each word in 1.txt to our vector:\n",
    "with open('sentence1.txt') as file:\n",
    "    sentence_file = file.read().lower().split()\n",
    "    \n",
    "for word in sentence_file:\n",
    "    one[vocab_dictionary[word]]+=1\n",
    "    \n",
    "print(one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentence 2', 1, 0, 1, 1, 1, 0, 0, 0, 2, 1, 0, 0, 0, 3, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Do the same for the second document:\n",
    "with open('sentence2.txt') as file:\n",
    "    sentence_file = file.read().lower().split()\n",
    "    \n",
    "for word in sentence_file:\n",
    "    two[vocab_dictionary[word]]+=1\n",
    "    \n",
    "print(two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentence 1', 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['sentence 2', 1, 0, 1, 1, 1, 0, 0, 0, 2, 1, 0, 0, 0, 3, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Compare the two vectors:\n",
    "print(f'{one}\\n{two}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
